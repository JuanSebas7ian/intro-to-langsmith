{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple RAG](../../images/simple_rag.png)\n",
    "\n",
    "In this notebook, we're going to set up a simple RAG application that we'll be using as we learn more about LangSmith.\n",
    "\n",
    "RAG (Retrieval Augmented Generation) is a popular technique for providing LLMs with relevant documents that will enable them to better answer questions from users. \n",
    "\n",
    "In our case, we are going to index some LangSmith documentation!\n",
    "\n",
    "LangSmith makes it easy to trace any LLM application, no LangChain required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set your environment variables, including your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline!\n",
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Fetching pages: 100%|##########| 364/364 [01:18<00:00,  4.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m bedrock_client = ChatBedrockConverse(model=MODEL_NAME)\n\u001b[32m     22\u001b[39m nest_asyncio.apply()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m retriever = \u001b[43mget_vector_db_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03mretrieve_documents\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m- Returns documents fetched from a vectorstore based on the user's question\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;129m@traceable\u001b[39m(run_type=\u001b[33m\"\u001b[39m\u001b[33mchain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_documents\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/notebooks/module_0/utils.py:37\u001b[39m, in \u001b[36mget_vector_db_retriever\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Limit to 100 chunks to avoid Bedrock rate limiting\u001b[39;00m\n\u001b[32m     36\u001b[39m doc_splits = doc_splits[:\u001b[32m100\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m vectorstore = \u001b[43mSKLearnVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoc_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m vectorstore.persist()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore.as_retriever(lambda_mult=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:814\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    812\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_community/vectorstores/sklearn.py:353\u001b[39m, in \u001b[36mSKLearnVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, persist_path, **kwargs)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m     **kwargs: Any,\n\u001b[32m    351\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mSKLearnVectorStore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    352\u001b[39m     vs = SKLearnVectorStore(embedding, persist_path=persist_path, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[43mvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_community/vectorstores/sklearn.py:206\u001b[39m, in \u001b[36mSKLearnVectorStore.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m _ids = ids \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;28mstr\u001b[39m(uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m _texts]\n\u001b[32m    205\u001b[39m \u001b[38;5;28mself\u001b[39m._texts.extend(_texts)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28mself\u001b[39m._embeddings.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_texts\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    207\u001b[39m \u001b[38;5;28mself\u001b[39m._metadatas.extend(metadatas \u001b[38;5;129;01mor\u001b[39;00m ([{}] * \u001b[38;5;28mlen\u001b[39m(_texts)))\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m._ids.extend(_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_aws/embeddings/bedrock.py:579\u001b[39m, in \u001b[36mBedrockEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_cohere_documents(texts)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iteratively_embed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_aws/embeddings/bedrock.py:592\u001b[39m, in \u001b[36mBedrockEmbeddings._iteratively_embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    590\u001b[39m results = []\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n\u001b[32m    595\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._normalize_vector(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_aws/embeddings/bedrock.py:283\u001b[39m, in \u001b[36mBedrockEmbeddings._embedding_func\u001b[39m\u001b[34m(self, text, input_type)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# includes common provider == \"amazon\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     response_body = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minputText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_dimensions_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m     embedding = response_body.get(\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/langchain_aws/embeddings/bedrock.py:326\u001b[39m, in \u001b[36mBedrockEmbeddings._invoke_model\u001b[39m\u001b[34m(self, input_body)\u001b[39m\n\u001b[32m    323\u001b[39m body = json.dumps(input_body)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m     response_metadata = response.get(\u001b[33m\"\u001b[39m\u001b[33mResponseMetadata\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response_metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/client.py:1060\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1056\u001b[39m     maybe_compress_request(\n\u001b[32m   1057\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.config, request_dict, operation_model\n\u001b[32m   1058\u001b[39m     )\n\u001b[32m   1059\u001b[39m     apply_request_checksum(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m     http, parsed_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1065\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1066\u001b[39m     http_response=http,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1069\u001b[39m     context=request_context,\n\u001b[32m   1070\u001b[39m )\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http.status_code >= \u001b[32m300\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/client.py:1084\u001b[39m, in \u001b[36mBaseClient._make_request\u001b[39m\u001b[34m(self, operation_model, request_dict, request_context)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[32m   1083\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1085\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1086\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1087\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._service_model.service_id.hyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1088\u001b[39m             exception=e,\n\u001b[32m   1089\u001b[39m             context=request_context,\n\u001b[32m   1090\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/endpoint.py:119\u001b[39m, in \u001b[36mEndpoint.make_request\u001b[39m\u001b[34m(self, operation_model, request_dict)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[32m    114\u001b[39m     logger.debug(\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         operation_model,\n\u001b[32m    117\u001b[39m         request_dict,\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/endpoint.py:200\u001b[39m, in \u001b[36mEndpoint._send_request\u001b[39m\u001b[34m(self, request_dict, operation_model)\u001b[39m\n\u001b[32m    196\u001b[39m request = \u001b[38;5;28mself\u001b[39m.create_request(request_dict, operation_model)\n\u001b[32m    197\u001b[39m success_response, exception = \u001b[38;5;28mself\u001b[39m._get_response(\n\u001b[32m    198\u001b[39m     request, operation_model, context\n\u001b[32m    199\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_needs_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43msuccess_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    207\u001b[39m     attempts += \u001b[32m1\u001b[39m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_retries_context(context, attempts, success_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/intro-to-langsmith/ls-academy/lib/python3.12/site-packages/botocore/endpoint.py:379\u001b[39m, in \u001b[36mEndpoint._needs_retry\u001b[39m\u001b[34m(self, attempts, operation_model, request_dict, response, caught_exception)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    373\u001b[39m     \u001b[38;5;66;03m# Request needs to be retried, and we need to sleep\u001b[39;00m\n\u001b[32m    374\u001b[39m     \u001b[38;5;66;03m# for the specified number of times.\u001b[39;00m\n\u001b[32m    375\u001b[39m     logger.debug(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mResponse received to retry, sleeping for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         handler_response,\n\u001b[32m    378\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "# from openai import OpenAI\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "# MODEL_PROVIDER = \"openai\"\n",
    "MODEL_PROVIDER = \"bedrock\"\n",
    "# MODEL_NAME = \"gpt-4o-mini\"\n",
    "MODEL_NAME = \"us.amazon.nova-2-lite-v1:0\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# openai_client = OpenAI()\n",
    "bedrock_client = ChatBedrockConverse(model=MODEL_NAME)\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_bedrock` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    # return call_bedrock(messages)\n",
    "    return call_bedrock(messages)\n",
    "\n",
    "\"\"\"\n",
    "call_bedrock\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_bedrock(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.0\n",
    ") -> str:\n",
    "    pass  # Comentado - usar call_bedrock\n",
    "    # return openai_client.chat.completions.create(\n",
    "    #     model=model,\n",
    "    #     messages=messages,\n",
    "    #     temperature=temperature,\n",
    "    # )\n",
    "\n",
    "def call_bedrock(messages: list) -> str:\n",
    "    lc_messages = []\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"system\":\n",
    "            lc_messages.append(SystemMessage(content=m[\"content\"]))\n",
    "        else:\n",
    "            lc_messages.append(HumanMessage(content=m[\"content\"]))\n",
    "    return bedrock_client.invoke(lc_messages)\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    # return response.choices[0].message.content\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should take a little less than a minute. We are indexing and storing LangSmith documentation in a SKLearn vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is LangSmith used for?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"website\": \"www.google.com\"}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look in LangSmith!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
